<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="//gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.102.3" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2022-01-17">
  <meta property="og:title" content="How Much Access to RAM Costs &middot; Developer&#39;s blog">
  <meta name="description" content="Every computer program uses the main memory (RAM) to store data. RAM is considered to be fast
storage compared even to the fastest NVMe SSD or 100Gbit network. It seems that the RAM speed is
high enough and that is why no optimizations are required: just read or write any memory cell when
the program needs it.
From the famous article
What Every Programmer Should Know About Memory,
I&rsquo;d found that memory access is more tricky than I used to think about.">
  <meta property="og:description" content="Every computer program uses the main memory (RAM) to store data. RAM is considered to be fast
storage compared even to the fastest NVMe SSD or 100Gbit network. It seems that the RAM speed is
high enough and that is why no optimizations are required: just read or write any memory cell when
the program needs it.
From the famous article
What Every Programmer Should Know About Memory,
I&rsquo;d found that memory access is more tricky than I used to think about.">
  <title>How Much Access to RAM Costs &middot; Developer&#39;s blog</title>
  

  
  <link type="text/css" rel="stylesheet" href="../../css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="../../css/poole.css">
  <link type="text/css" rel="stylesheet" href="../../css/syntax.css">
  <link type="text/css" rel="stylesheet" href="../../css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../../apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="../../favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Developer&#39;s blog" />
</head>

  <body>
    <header class="site-title">
      <h1><a href="../../">Developer's blog</a></h1>
      <h4><a href="../../notes">Go to Notes</a></h4>
    </header>
    <main class="container">
    <div class="post">
  <h1 class="post-title">How Much Access to RAM Costs</h1>
  <time datetime=2022-01-17T05:00:00Z class="post-date">Jan 17, 2022</time>
  <p>Every computer program uses the main memory (RAM) to store data. RAM is considered to be fast
storage compared even to the fastest NVMe SSD or 100Gbit network. It seems that the RAM speed is
high enough and that is why no optimizations are required: just read or write any memory cell when
the program needs it.</p>
<p>From the famous article
<a href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">What Every Programmer Should Know About Memory</a>,
I&rsquo;d found that memory access is more tricky than I used to think about.</p>
<p>Modern CPUs have a small amount of blazing-fast internal memory â€”
<a href="https://en.wikipedia.org/wiki/Processor_register">the registers</a>. There is no delay when accessing
data from the registers, <a href="https://en.wikipedia.org/wiki/Execution_unit">the functional units</a> can
operate on this data directly. Each CPU core has its own registers, so the access time does not
depend on the other cores&rsquo; load.</p>
<p>If there is no requested data in the CPU registers it should be loaded from the RAM to execute
operations on it. Accessing the RAM is 10 times slower than accessing the registers, so the CPU has
to request the data and wait a significant amount of time before it will be loaded into the
registers. Also, there is a shared bus between the RAM and CPUs, that is why if one core actively
access the RAM it can influence the accesses time for the other cores.</p>
<p>To reduce the average cost to access data from the main memory a mechanism called
<a href="https://en.wikipedia.org/wiki/CPU_cache">CPU cache</a> was introduced. It&rsquo;s a small amount of fast
on-chip memory, which stores copies of the data from the RAM. An access time to the cache is much
smaller than to the RAM. Most CPUs have a hierarchy of multiple cache levels (L1, L2, L3). Each next
level of cache is bigger but slower.</p>
<p>Data is transferred from the RAM and stored in the cache in blocks of fixed size, called cache
lines. When the CPU needs to read a location in memory, it first checks for a corresponding entry in
the cache. If the requested data is not found in the cache, a <em>cache miss</em> is occurred. A cache miss
is quite expensive because it requires not only to load new data from the memory into the cache but
also to evict one of the existing entries. That is why one of the crucial software developer&rsquo;s tasks
is organizing memory access of the program in such a way that minimizes the number of cache misses.</p>
<p>Consider the practical task. Matrix multiplication is one of the most important matrix operations.
It is used widely in such areas as machine learning or 3D graphics. For the huge matrices, the
computations can take a lot of time, so the optimization of this operation can increase the speed of
the whole program significantly.</p>
<p>The description of an algorithm can be easily found on
<a href="https://en.wikipedia.org/wiki/Matrix_multiplication">Wikipedia</a>.</p>
<p>The naive Plain C implementation looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#dc322f">void</span> <span style="color:#268bd2">matrix_multiply</span>(size_t sz, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>mul1, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>mul2, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>res) {
</span></span><span style="display:flex;"><span>  size_t i, j, k;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#719e07">for</span> (i <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; i <span style="color:#719e07">&lt;</span> sz; i<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">for</span> (j <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; j <span style="color:#719e07">&lt;</span> sz; j<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>      <span style="color:#719e07">for</span> (k <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; k <span style="color:#719e07">&lt;</span> sz; k<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>        res[i][j] <span style="color:#719e07">+=</span> mul1[i][k] <span style="color:#719e07">*</span> mul2[k][j];
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The function receives two square matrices <code>mul1</code> and <code>mul2</code> of size <code>sz x sz</code> and calculates their
multiplication into <code>res</code>. It&rsquo;s expected, that <code>res</code> is initialized by zeros.</p>
<p>Assume the matrix of size <code>1000x1000</code>. In this case, CPU cache can&rsquo;t hold an entire matrix. In the
inner loop, the elements of <code>mul1</code> are accessed sequentially, so it uses CPU cache effectively. For
the <code>mul2</code> argument, the elements are accessed more-or-less randomly. For each element of the result
matrix, 1000 random elements should be retrieved from the RAM.</p>
<p>I got such measurements on my PC:</p>
<table>
<thead>
<tr>
<th>matrix size</th>
<th>execution time in cycles</th>
</tr>
</thead>
<tbody>
<tr>
<td>100x100</td>
<td>733</td>
</tr>
<tr>
<td>300x300</td>
<td>21485</td>
</tr>
<tr>
<td>500x500</td>
<td>101610</td>
</tr>
<tr>
<td>1000x1000</td>
<td>843546</td>
</tr>
<tr>
<td>2000x2000</td>
<td>25787985</td>
</tr>
<tr>
<td>3000x3000</td>
<td>107763896</td>
</tr>
</tbody>
</table>
<p>First optimization is a <code>mul2</code> transposition:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#dc322f">void</span> <span style="color:#268bd2">matrix_multiply_t</span>(size_t sz, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>mul1, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>mul2, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>res) {
</span></span><span style="display:flex;"><span>  size_t i, j, k;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#dc322f">double</span> tmp;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#719e07">for</span> (i <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; i <span style="color:#719e07">&lt;</span> sz; i<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">for</span> (j <span style="color:#719e07">=</span> i; j <span style="color:#719e07">&lt;</span> sz; j<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>      tmp <span style="color:#719e07">=</span> mul2[i][j];
</span></span><span style="display:flex;"><span>      mul2[i][j] <span style="color:#719e07">=</span> mul2[j][i];
</span></span><span style="display:flex;"><span>      mul2[j][i] <span style="color:#719e07">=</span> tmp;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#719e07">for</span> (i <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; i <span style="color:#719e07">&lt;</span> sz; i<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">for</span> (j <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; j <span style="color:#719e07">&lt;</span> sz; j<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>      <span style="color:#719e07">for</span> (k <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; k <span style="color:#719e07">&lt;</span> sz; k<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>        res[i][j] <span style="color:#719e07">+=</span> mul1[i][k] <span style="color:#719e07">*</span> mul2[j][k];
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>After <code>mul2</code> transposition, it&rsquo;s possible to access both arguments sequentially, so CPU cache is
used effectively. The function needs some time for the transposition operation that is why the
results can be similar to naive implementation for small input matrices.</p>
<p>The function modifies <code>mul2</code> argument, that is why it can&rsquo;t be used further. It&rsquo;s possible to make a
copy of <code>mul2</code>, but in this case, the function requires additional memory, so the software developer
should decide what is the best option for the particular task.</p>
<p>The execution results:</p>
<table>
<thead>
<tr>
<th>matrix size</th>
<th>execution time (cycles)</th>
<th>relative execution time</th>
</tr>
</thead>
<tbody>
<tr>
<td>100x100</td>
<td>719</td>
<td>98.09%</td>
</tr>
<tr>
<td>300x300</td>
<td>20885</td>
<td>97.21%</td>
</tr>
<tr>
<td>500x500</td>
<td>96832</td>
<td>95.30%</td>
</tr>
<tr>
<td>1000x1000</td>
<td>788834</td>
<td>93.51%</td>
</tr>
<tr>
<td>2000x2000</td>
<td>7268999</td>
<td>28.19%</td>
</tr>
<tr>
<td>3000x3000</td>
<td>24179636</td>
<td>22.44%</td>
</tr>
</tbody>
</table>
<p>The second optimization is accessing data in such a way that utilizes CPU cache as much as possible
without matrix transposition:</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#719e07">#define SM (CLS / sizeof(double))
</span></span></span><span style="display:flex;"><span><span style="color:#719e07"></span>
</span></span><span style="display:flex;"><span><span style="color:#dc322f">void</span> <span style="color:#268bd2">matrix_multiply_fast</span>(size_t sz, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>mul1, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>mul2, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>res) {
</span></span><span style="display:flex;"><span>  size_t i, i2, j, j2, k, k2;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#719e07">for</span> (i <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; i <span style="color:#719e07">&lt;</span> sz; i <span style="color:#719e07">+=</span> SM) {
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">for</span> (j <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; j <span style="color:#719e07">&lt;</span> sz; j <span style="color:#719e07">+=</span> SM) {
</span></span><span style="display:flex;"><span>      <span style="color:#719e07">for</span> (k <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; k <span style="color:#719e07">&lt;</span> sz; k <span style="color:#719e07">+=</span> SM) {
</span></span><span style="display:flex;"><span>        size_t i2_max <span style="color:#719e07">=</span> MIN(SM, sz <span style="color:#719e07">-</span> i);
</span></span><span style="display:flex;"><span>        <span style="color:#719e07">for</span> (i2 <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; i2 <span style="color:#719e07">&lt;</span> i2_max; i2<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>          <span style="color:#dc322f">double</span> <span style="color:#719e07">*</span>rres <span style="color:#719e07">=</span> res[i <span style="color:#719e07">+</span> i2] <span style="color:#719e07">+</span> j;
</span></span><span style="display:flex;"><span>          <span style="color:#dc322f">double</span> <span style="color:#719e07">*</span>rmul1 <span style="color:#719e07">=</span> mul1[i <span style="color:#719e07">+</span> i2] <span style="color:#719e07">+</span> k;
</span></span><span style="display:flex;"><span>          size_t k2_max <span style="color:#719e07">=</span> MIN(SM, sz <span style="color:#719e07">-</span> k);
</span></span><span style="display:flex;"><span>          <span style="color:#719e07">for</span> (k2 <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; k2 <span style="color:#719e07">&lt;</span> k2_max; k2<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>            <span style="color:#dc322f">double</span> <span style="color:#719e07">*</span>rmul2 <span style="color:#719e07">=</span> mul2[k <span style="color:#719e07">+</span> k2] <span style="color:#719e07">+</span> j;
</span></span><span style="display:flex;"><span>            size_t j2_max <span style="color:#719e07">=</span> MIN(SM, sz <span style="color:#719e07">-</span> j);
</span></span><span style="display:flex;"><span>            <span style="color:#719e07">for</span> (j2 <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; j2 <span style="color:#719e07">&lt;</span> j2_max; j2<span style="color:#719e07">++</span>) {
</span></span><span style="display:flex;"><span>              res[i <span style="color:#719e07">+</span> i2][j <span style="color:#719e07">+</span> j2] <span style="color:#719e07">+=</span> mul1[i <span style="color:#719e07">+</span> i2][k <span style="color:#719e07">+</span> k2] <span style="color:#719e07">*</span> mul2[j <span style="color:#719e07">+</span> j2][k <span style="color:#719e07">+</span> k2];
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>          }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The algorithm makes the same calculations as a naive implementation but in a different order. There
are six nested loops. The outer loops iterate with intervals of SM (the cache line size divided by
<code>sizeof(double)</code>). This divides the multiplication into several smaller problems which can be
handled with more cache locality. The inner loops iterate over the missing indexes of the outer
loops. <code>k2</code> and <code>j2</code> loops are in a different order because, in the actual computation, only one
expression depends on <code>k2</code> but two depend on <code>j2</code>.</p>
<p><code>CLS</code> macro is defined by the command <code>getconf LEVEL1_DCACHE_LINESIZE</code> during the compilation. This
command returns L1 cache line size, so it makes it possible for inner loops to utilize CPU cache
effectively.</p>
<p>The execution results:</p>
<table>
<thead>
<tr>
<th>matrix size</th>
<th>execution time (cycles)</th>
<th>relative execution time</th>
</tr>
</thead>
<tbody>
<tr>
<td>100x100</td>
<td>606</td>
<td>82.67%</td>
</tr>
<tr>
<td>300x300</td>
<td>15503</td>
<td>72.16%</td>
</tr>
<tr>
<td>500x500</td>
<td>72558</td>
<td>71.41%</td>
</tr>
<tr>
<td>1000x1000</td>
<td>600223</td>
<td>71.15%</td>
</tr>
<tr>
<td>2000x2000</td>
<td>5203588</td>
<td>20.18%</td>
</tr>
<tr>
<td>3000x3000</td>
<td>17501126</td>
<td>16.24%</td>
</tr>
</tbody>
</table>
<p>The most optimized version can be found in the
<a href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">article</a> (p.50):</p>
<div class="highlight"><pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#719e07">#define SM (CLS / sizeof(double))
</span></span></span><span style="display:flex;"><span><span style="color:#719e07"></span>
</span></span><span style="display:flex;"><span><span style="color:#dc322f">void</span> <span style="color:#268bd2">matrix_multiply_seq</span>(size_t sz, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>mul1, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>mul2, <span style="color:#dc322f">double</span> <span style="color:#719e07">**</span>res) {
</span></span><span style="display:flex;"><span>  size_t i, i2, j, j2, k, k2;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#dc322f">double</span> <span style="color:#719e07">*</span>rres, <span style="color:#719e07">*</span>rmul1, <span style="color:#719e07">*</span>rmul2;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#719e07">for</span> (i <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; i <span style="color:#719e07">&lt;</span> sz; i <span style="color:#719e07">+=</span> SM) {
</span></span><span style="display:flex;"><span>    <span style="color:#719e07">for</span> (j <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; j <span style="color:#719e07">&lt;</span> sz; j <span style="color:#719e07">+=</span> SM) {
</span></span><span style="display:flex;"><span>      <span style="color:#719e07">for</span> (k <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; k <span style="color:#719e07">&lt;</span> sz; k <span style="color:#719e07">+=</span> SM) {
</span></span><span style="display:flex;"><span>        size_t i2_max <span style="color:#719e07">=</span> MIN(SM, sz <span style="color:#719e07">-</span> i);
</span></span><span style="display:flex;"><span>        <span style="color:#719e07">for</span> (i2 <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>, rres <span style="color:#719e07">=</span> <span style="color:#719e07">&amp;</span>res[i][j], rmul1 <span style="color:#719e07">=</span> <span style="color:#719e07">&amp;</span>mul1[i][k]; i2 <span style="color:#719e07">&lt;</span> i2_max; <span style="color:#719e07">++</span>i2, rres <span style="color:#719e07">+=</span> sz, rmul1 <span style="color:#719e07">+=</span> sz) {
</span></span><span style="display:flex;"><span>          size_t k2_max <span style="color:#719e07">=</span> MIN(SM, sz <span style="color:#719e07">-</span> k);
</span></span><span style="display:flex;"><span>          <span style="color:#719e07">for</span> (k2 <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>, rmul2 <span style="color:#719e07">=</span> <span style="color:#719e07">&amp;</span>mul2[k][j]; k2 <span style="color:#719e07">&lt;</span> k2_max; <span style="color:#719e07">++</span>k2, rmul2 <span style="color:#719e07">+=</span> sz) {
</span></span><span style="display:flex;"><span>            size_t j2_max <span style="color:#719e07">=</span> MIN(SM, sz <span style="color:#719e07">-</span> j);
</span></span><span style="display:flex;"><span>            <span style="color:#719e07">for</span> (j2 <span style="color:#719e07">=</span> <span style="color:#2aa198">0</span>; j2 <span style="color:#719e07">&lt;</span> j2_max; <span style="color:#719e07">++</span>j2) {
</span></span><span style="display:flex;"><span>              rres[j2] <span style="color:#719e07">+=</span> rmul1[k2] <span style="color:#719e07">*</span> rmul2[j2];
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>          }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Compared to <code>matrix_multiply_fast</code> this function uses temp variables to hold intermediate values and
also uses <code>+= sz</code> instruction to iterate over the matrices. As a result, the compilation produces
more compact machine code, so less instruction should be executed for each iteration.</p>
<p>This function requires data to be stored sequentially in the memory, so
<code>mul1[i + 1][0] == (mul1[i] + sz)[0]</code>.</p>
<p>The execution results:</p>
<table>
<thead>
<tr>
<th>matrix size</th>
<th>execution time (cycles)</th>
<th>relative execution time</th>
</tr>
</thead>
<tbody>
<tr>
<td>100x100</td>
<td>459</td>
<td>62.62%</td>
</tr>
<tr>
<td>300x300</td>
<td>11773</td>
<td>54.80%</td>
</tr>
<tr>
<td>500x500</td>
<td>56441</td>
<td>55.55%</td>
</tr>
<tr>
<td>1000x1000</td>
<td>480246</td>
<td>56.93%</td>
</tr>
<tr>
<td>2000x2000</td>
<td>4164429</td>
<td>16.15%</td>
</tr>
<tr>
<td>3000x3000</td>
<td>14001852</td>
<td>12.99%</td>
</tr>
</tbody>
</table>
<p>From the results, it can be found that execution time does not differ a lot for small matrices, but
as matrices become bigger the difference grows significantly, that is why the optimizations are
worth implementing.</p>
<p><img src="../../matrix-multiply-speed.png" alt="algorithms comparation"></p>
<p>I run all examples on the machine with Intel Core i7-10700K processor and 3000 MHz DDR4 memory on
Ubuntu 20.04 with gcc 9.3.0.</p>
<p>I&rsquo;d uploaded the code I&rsquo;d used into
<a href="https://github.com/0e39bf7b/matrices-multiplication">GitHub repo</a>, so anyone can run it and measure
an execution time on the different hardware.</p>
<p>Concluding, writing the code considering cache locality can increase the performance dramatically,
but sometimes it can make the program harder to read and understand. As Donald Knuth had written in
The Art of Computer Programming: &ldquo;Premature optimization is the root of all evil&rdquo;, so make such
performance tuning if only it&rsquo;s required.</p>
</div>
    </main>
  </body>
</html>

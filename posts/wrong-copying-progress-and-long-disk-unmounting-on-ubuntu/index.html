<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="//gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.87.0" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2021-01-04">
  <meta property="og:title" content="Wrong Copying Progress and Long Disk Unmounting on Ubuntu &middot; Developer&#39;s blog">
  <meta name="description" content="
Sometimes I need to copy files from an internal SSD to an external hard drive. Recently I&rsquo;ve found a
strange behavior on Ubuntu 20.04. When I try to copy a fairly big file (like 2Gb - 4Gb) Nautilus
shows insane writing speed and the progress bar instantly reaches 100%, but when I want to unmount
the device - it freezes for several minutes. I tried different file managers like
Thunar from Xfce,
midnight-commander, or even utilities like rsync or pv - the
result was the same. For me, it&rsquo;s a bit inconvenient when I don&rsquo;t know how much time I have to wait
until all data will be transferred, so I tried to find the solution to this problem.">
  <meta property="og:description" content="
Sometimes I need to copy files from an internal SSD to an external hard drive. Recently I&rsquo;ve found a
strange behavior on Ubuntu 20.04. When I try to copy a fairly big file (like 2Gb - 4Gb) Nautilus
shows insane writing speed and the progress bar instantly reaches 100%, but when I want to unmount
the device - it freezes for several minutes. I tried different file managers like
Thunar from Xfce,
midnight-commander, or even utilities like rsync or pv - the
result was the same. For me, it&rsquo;s a bit inconvenient when I don&rsquo;t know how much time I have to wait
until all data will be transferred, so I tried to find the solution to this problem.">
  <title>Wrong Copying Progress and Long Disk Unmounting on Ubuntu &middot; Developer&#39;s blog</title>
  

  
  <link type="text/css" rel="stylesheet" href="https://0e39bf7b.blog/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://0e39bf7b.blog/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://0e39bf7b.blog/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://0e39bf7b.blog/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Developer&#39;s blog" />
</head>

  <body>
    <header class="site-title">
      <h1><a href="https://0e39bf7b.blog/">Developer&#39;s blog</a></h1>
    </header>
    <main class="container">
    <div class="post">
  <h1 class="post-title">Wrong Copying Progress and Long Disk Unmounting on Ubuntu</h1>
  <time datetime=2021-01-04T11:00:00Z class="post-date">Jan 4, 2021</time>
  <p><img src="/unmount-freezes.png" alt="Unmount freezes"></p>
<p>Sometimes I need to copy files from an internal SSD to an external hard drive. Recently I&rsquo;ve found a
strange behavior on Ubuntu 20.04. When I try to copy a fairly big file (like 2Gb - 4Gb) Nautilus
shows insane writing speed and the progress bar instantly reaches 100%, but when I want to unmount
the device - it freezes for several minutes. I tried different file managers like
<a href="https://docs.xfce.org/xfce/thunar/start">Thunar</a> from Xfce,
<a href="https://midnight-commander.org/">midnight-commander</a>, or even utilities like <code>rsync</code> or <code>pv</code> - the
result was the same. For me, it&rsquo;s a bit inconvenient when I don&rsquo;t know how much time I have to wait
until all data will be transferred, so I tried to find the solution to this problem.</p>
<p>Searching on the Internet leads me to the fact that this problem is not specified to the file
manager or Linux distribution. It can be explained by the Linux virtual memory subsystem and
<a href="https://en.wikipedia.org/wiki/Page_cache">page cache</a> mechanism.</p>
<p>All types of computer memory can be divided into two groups: volatile and non-volatile. Volatile
memory usually fast but it has a limited size and requires power to maintain the stored information.
In contrast, non-volatile memory like HDD or the optical disc can retain the stored information even
after power is removed but it&rsquo;s slower than RAM. Due to this fact, Linux and other operating systems
use different approaches for accessing the memory of different kinds.</p>
<p>RAM is fast enough, that is why when a process needs to access the RAM it just specifies an address
and waits until the operation completes. For non-volatile storage, such an algorithm increases
latency and makes the system unresponsive, so it&rsquo;s better to use the asynchronous approach as much
as possible. Linux stages disk writes into the cache in RAM, and over time asynchronously flushes
them to disk. This algorithm has a positive effect on speeding disk I/O, but it has some issues.</p>
<p>When the cache is empty, and a process tries to execute a <code>write</code> operation it receives almost
instant feedback, but when the <code>flush</code> command is called there is a large pause for the actual data
transfer between RAM and HDD. By default, Ubuntu uses 20% of RAM for file caches that is why when I
have a lot of free RAM the cache can hold the whole file what leads to the problem described in the
first paragraph.</p>
<p>There are several possible solutions.</p>
<h4 id="reduce-cache-size">Reduce cache size</h4>
<p>There are some tunable settings that influence how the Linux kernel deals with the file system
cache. All of them are connected with dirty data (or dirty memory) - data that is written into the
cache but not saved on disk.</p>
<ul>
<li><code>dirty_ratio</code> - maximum percentage of dirty system memory</li>
<li><code>dirty_bytes</code> - the same as <code>dirty_ratio</code> but specified in bytes</li>
<li><code>dirty_background_ratio</code> - percentage of dirty system memory at which background writeback will
start</li>
<li><code>dirty_background_bytes</code> - the same as <code>dirty_background_ratio</code> but specified in bytes</li>
</ul>
<p>If my computer has 32Gb of RAM and <code>dirty_ratio</code> is 20 then the cache size will be over 6Gb what
leads to a long unmounting time. It&rsquo;s possible to reduce cache size to 48Mb and ask operating system
to start writing to the device when the cache has more than 16Mb of data using the command:</p>
<pre><code>sudo bash -c 'echo $((16*1024*1024)) &gt; /proc/sys/vm/dirty_background_bytes'
sudo bash -c 'echo $((48*1024*1024)) &gt; /proc/sys/vm/dirty_bytes'
</code></pre><p>In this case, coping progress shows correct speed, and unmounting takes only several seconds.
To save this setting after reboot it&rsquo;s required to add such a line into <code>/etc/sysctl.conf</code>:</p>
<pre><code>vm.dirty_background_bytes = 16777216
vm.dirty_bytes = 50331648
</code></pre><p>This option is applied to all disks - external and internal ones what can reduce system performance.</p>
<h4 id="mount-usb-flash-drive-with-sync-or-flush-option">Mount USB flash drive with &ldquo;sync&rdquo; or &ldquo;flush&rdquo; option</h4>
<p>By default, Ubuntu mounts flash drives with the <code>async</code> option. It means that cache and asynchronous
writes will be used. It&rsquo;s possible to ask the kernel to write all data synchronously. Assume flash
drive is a <code>/dev/sda1</code> device and it&rsquo;s required to mount it on <code>/mnt</code> directory. I can use a command
like:</p>
<pre><code>sudo mount /dev/sda1 /mnt -o rw,sync
</code></pre><p>This option can
<a href="https://askubuntu.com/questions/1176927/is-there-an-alternative-to-the-sync-option-of-mount-when-mounting-an-external">reduce write speed dramatically</a>
and moreover it can influence the lifetime of the device: Linux kernel can&rsquo;t reorder writes and has
to write every sector in the order requested by the applications. On cheap USB drives that don&rsquo;t
reallocate sectors, the repeated writes to the file allocation table on (V)FAT or to the journal on
a typical modern filesystem can kill the stick
<a href="http://readlist.com/lists/vger.kernel.org/linux-kernel/22/111748.html">pretty fast</a>.</p>
<p>On FAT filesystems it&rsquo;s possible to use the <code>flush</code> option instead of <code>sync</code>. It asks the kernel to
flush all writes as soon as the drive becomes idle, but it does not preserve the order of writes, so
the kernel can optimize the write process.</p>
<h4 id="use-autofsync">Use autofsync</h4>
<p>On Ubuntu, it&rsquo;s possible to intercept some system calls for a process and add custom behavior. This
idea is used in the library called <a href="https://github.com/i-rinat/autofsync">autofsync</a>. It intercepts
<code>write()</code> call and performs <code>sync</code> operation when a certain amount of data were written to a file.
Limit size is adjusted at run time to keep <code>sync</code> durations around predefined value. The goal is to
express the writeback cache size limit in seconds rather than in bytes.</p>
<p>The library should be attached to the process using <code>LD_PRELOAD</code>:</p>
<pre><code># Download and build library
git clone https://github.com/i-rinat/autofsync.git
cd autofsync
cmake .
make

# Start file manager
LD_PRELOAD=$PWD/autofsync.so mc
</code></pre><p>I prefer this method because it does not depend on the RAM size, flash drive speed, and also it is
filesystem independent solution. It changes the behavior of a particular process and does not affect
the whole system&rsquo;s performance.</p>
<h4 id="conclusion">Conclusion</h4>
<p>Using external disks is a rare operation nowadays, but it does not mean that it should be
inconvenient, so one of the solutions from the article can make the user experience much better.</p>
</div>
    </main>
  </body>
</html>
